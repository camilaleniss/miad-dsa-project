{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum tolerated null value amount is 49131\n",
      "Mocodes will be deleted because it has 145262 null values and this is 96131 values more than tolerance\n",
      "Vict Sex will be deleted because it has 138445 null values and this is 89314 values more than tolerance\n",
      "Vict Descent will be deleted because it has 138456 null values and this is 89325 values more than tolerance\n",
      "Weapon Used Cd will be deleted because it has 656471 null values and this is 607340 values more than tolerance\n",
      "Crm Cd 2 will be deleted because it has 913763 null values and this is 864632 values more than tolerance\n",
      "Crm Cd 3 will be deleted because it has 980327 null values and this is 931196 values more than tolerance\n",
      "Crm Cd 4 will be deleted because it has 982574 null values and this is 933443 values more than tolerance\n",
      "Cross Street will be deleted because it has 830789 null values and this is 781658 values more than tolerance\n",
      "The maximum tolerated unique value amount is 982.0 in string data\n",
      "Rpt Dist No might be deleted because it has 1209 unique values and this is 227.0 values more than tolerance\n",
      "LOCATION might be deleted because it has 66265 unique values and this is 65283.0 values more than tolerance\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Crime_Data_from_2020_to_Present.csv')\n",
    "from wolta.data_tools import col_types\n",
    "types = col_types(df, print_columns=False)\n",
    "from wolta.data_tools import seek_null\n",
    "seeked = seek_null(df, print_columns=False)\n",
    "\n",
    "df['Rpt Dist No'] = df['Rpt Dist No'].astype(str)\n",
    "#Eliminar features con % de missing values\n",
    "from wolta.feature_tools import list_deletings\n",
    "df = list_deletings(df, extra=['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'Premis Desc', 'Weapon Desc', 'AREA NAME', 'Crm Cd Desc'], unique_tolerance=0.1, null_tolerance=5)\n",
    "\n",
    "del df['LOCATION']\n",
    "seeked = seek_null(df, print_columns=False)\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "# Convertir colkumnas str a numeric\n",
    "from wolta.data_tools import make_numerics\n",
    "\n",
    "types = col_types(df)\n",
    "loc = 0\n",
    "\n",
    "for col in df.columns:\n",
    "    if types[loc] == 'str':\n",
    "        df[col] = make_numerics(df[col])\n",
    "    \n",
    "    loc += 1\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "df = df.sample(frac=0.4, random_state=42) # se toma un 40 % de los registro originales para reducir el tiempo de computo para el ejercicio\n",
    "features = df.drop(columns=['Part 1-2'])  # Variables independientes\n",
    "target = df['Part 1-2']  # Variable dependiente\n",
    "\n",
    "# Dividir el dataset en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model and PKL file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9999491152854773\n",
      "Accuracy: 0.999949115457028\n",
      "Modelo serializado y guardado como 'best_random_forest_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import joblib  # Para serializar el modelo\n",
    "\n",
    "\n",
    "# Configurar el modelo con los mejores parámetros\n",
    "best_model = RandomForestClassifier(max_depth=20, n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Serializar el modelo entrenado\n",
    "joblib.dump(best_model, 'best_random_forest_model.pkl')\n",
    "print(\"Modelo serializado y guardado como 'best_random_forest_model.pkl'\")\n",
    "\n",
    "# NOTA: Variable independiente: Part 1-2: Indicates whether the crime is a Part 1 (serious) or Part 2 (less serious) offense.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
